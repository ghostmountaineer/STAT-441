{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "HW_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS-E9KWjVOYs"
      },
      "source": [
        "# Homework 6\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Some questions refer you to the [ISL textbook](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf). You may work with other students in the class to solve the problems but should write up your solutions separately.  Some textbook problem solutions are available on the internet.  You are welcome to look at these after attempting the problem yourself first, but please write up your solutions in your own words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU3kenicVOY4"
      },
      "source": [
        "## Conceptual Problems\n",
        "Do problem 3 in Chapter 9.7  and problem 3 of Chapter  10.5 of ISL. \n",
        "\n",
        "Additionally, find the eigenvectors and eigenvalues of $Cov(X) = X^TX$ when the data $X$ consists of the following four points: $(-2, -1)$, $(-1, -2)$, $(2, 1)$ and $(1, 2)$.  Draw a graph showing these four points and the eigenvectors.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItM0SkPAVbSq"
      },
      "source": [
        "## Decision trees\n",
        "\n",
        "Split the [Auto](http://math.oit.edu/~overholserr/current/math407/hw/cleanAuto.csv) dataset into a test and train set.  Make a simple decision tree on the numerical predictors with a maximum of 10 leaves to predict mpg.  You may find this [example](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py) helpful.\n",
        "Print the tree and find MAE on your test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3beCcWSVOY5"
      },
      "source": [
        "## Support Vector Machines: Problem 9.7.7\n",
        "\n",
        "Read the lab in Chapter 9.6.  There is a Python version [here](https://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%209.ipynb)\n",
        "\n",
        "Try problem 9.7.7 for the [Auto](http://math.oit.edu/~overholserr/current/math407/hw/cleanAuto.csv) dataset.  To turn in: your recommended SVM settings to predict high or low mpg (i.e. radial with gamma = xx, or poly with degree = xx, cost = xx) and the test error associated with your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcM4_yfzVOY7"
      },
      "source": [
        "your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-k2YfrVOY8"
      },
      "source": [
        "## Support Vector Machines: Problem 9.7.8\n",
        "Read the lab in Chapter 9.6.  There is a Python version [here](https://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%209.ipynb)\n",
        "\n",
        "Try problem 9.7.8 for the [OJ](http://math.oit.edu/~overholserr/current/math407/hw/OJ.csv) dataset.  To turn in: your answer to part (h): overall, which approach seems to give the best results on this data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nl0uqqAVOY-"
      },
      "source": [
        "your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ZlIQwQVOZA"
      },
      "source": [
        "## K-means with Iris dataset\n",
        "\n",
        "Download the [iris](https://www.kaggle.com/uciml/iris) dataset.   Read the labs in Chapter 10.4, then perform k-means clustering with k=3 on the lengths and widths of the sepals and petals of the iris.  Repeat k-means clustering but first standardize the 4 predictors to have the same scale. A Python version is available [here](https://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%2010.ipynb).\n",
        "To turn in: How well does the clustering match the actual three species?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enFU9Zg5VOZB"
      },
      "source": [
        "your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x19WbsutVOZI"
      },
      "source": [
        "## PCA with Iris dataset\n",
        "\n",
        "Download the [iris](https://www.kaggle.com/uciml/iris) dataset.  Read the labs in Chapter 10.4, then perform PCA on the lengths and widths of the sepals and petals of the iris.  Repeat PCA but first standardize the 4 predictors to have the same scale. A Python version is available [here](https://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%2010.ipynb).\n",
        "To turn in: How many components are needed to explain 90% of the variation in the lengths and widths of the sepals and petals?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtTPGwZxVOZK"
      },
      "source": [
        "your answer"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}